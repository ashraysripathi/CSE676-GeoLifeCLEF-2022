{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nos.environ[\"XRT_TPU_CONFIG\"] = \"tpu_worker;0;10.0.0.2:8470\"","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:15:19.505544Z","iopub.execute_input":"2022-05-22T15:15:19.505963Z","iopub.status.idle":"2022-05-22T15:15:19.535996Z","shell.execute_reply.started":"2022-05-22T15:15:19.505867Z","shell.execute_reply":"2022-05-22T15:15:19.535113Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Creating Pipeline to load the dataset for Training","metadata":{}},{"cell_type":"code","source":"!pip install timm\n!rm -rf GLC\n!git clone https://github.com/maximiliense/GLC\nimport timm\nfrom GLC.metrics import top_30_error_rate\nimport pytorch_lightning as pl\nimport torch\nimport os\nfrom pathlib import Path\nimport pandas as pd\n\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport albumentations as A\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom skimage.io import imread\nimport numpy as np\n\n\ndef get_patch_image(sample, image, path=\"../input/geolifeclef-2022-lifeclef-2022-fgvc9\"):\n    patch = get_patch(sample, path)\n    return patch + '/' + str(sample) + '_' + image\n\n\ndef get_patch_rgb(sample, path=\"../input/geolifeclef-2022-lifeclef-2022-fgvc9\"):\n    return get_patch_image(sample, 'rgb.jpg', path)\n\n\ndef get_patch(sample, path=\"../input/geolifeclef-2022-lifeclef-2022-fgvc9\"):\n    country_id = str(sample)[0]\n    country = 'fr' if country_id == '1' else 'us'\n    subfolder = str(sample)[-2:]\n    subsubfolder = str(sample)[-4:-2]\n    return path + '/patches-' + country + '/' + subfolder + '/' + subsubfolder\n\n\ndef get_country(sample, path=\"../input/geolifeclef-2022-lifeclef-2022-fgvc9\"):\n    country_id = str(sample)[0]\n    country = 0 if country_id == '1' else 1\n    return country\n\n\nclass RGBDataset(torch.utils.data.Dataset):\n    def __init__(self, images, labels=None, trans=None):\n        self.images = images\n        self.labels = labels\n        self.trans = trans\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, ix):\n        img = imread(self.images[ix])\n        if self.trans is not None:\n            img = self.trans(image=img)['image']\n        if self.labels is not None:\n            label = self.labels[ix]\n            return img, label\n        observation_id = self.images[ix].split('/')[-1].split('_')[0]\n        return img, observation_id\n\n\nclass RGNirDataset(torch.utils.data.Dataset):\n    def __init__(self, observation_ids, labels=None, trans=None):\n        self.observation_ids = observation_ids\n        self.labels = labels\n        self.trans = trans\n\n    def __len__(self):\n        return len(self.observation_ids)\n\n    def __getitem__(self, ix):\n        observation_id = self.observation_ids[ix]\n        patch = get_patch(observation_id)\n        rgb = patch + '/' + str(observation_id) + '_rgb.jpg'\n        rgb = imread(rgb)\n        nir = patch + '/' + str(observation_id) + '_near_ir.jpg'\n        nir = imread(nir)\n        img = np.concatenate(\n            (rgb[..., :2], np.expand_dims(nir, axis=-1)), axis=2)\n        if self.trans is not None:\n            img = self.trans(image=img)['image']\n        if self.labels is not None:\n            label = self.labels[ix]\n            return img, label\n        return img, observation_id\n\n\nclass RGBDataModule(pl.LightningDataModule):\n    def __init__(self, batch_size=32, path=\"../input/geolifeclef-2022-lifeclef-2022-fgvc9\", num_workers=0, pin_memory=False, train_trans=None):\n        super().__init__()\n        self.batch_size = batch_size\n        self.path = Path(path)\n        self.num_workers = num_workers\n        self.pin_memory = pin_memory\n        self.train_trans = train_trans\n\n    def read_data(self, mode=\"train\"):\n        obs_fr = pd.read_csv(self.path / 'observations' /\n                             f'observations_fr_{mode}.csv', sep=';')\n        obs_us = pd.read_csv(self.path / 'observations' /\n                             f'observations_us_{mode}.csv', sep=';')\n        return pd.concat([obs_fr, obs_us])\n\n    def split_data(self):\n        self.data_train = self.data[self.data['subset'] == 'train']\n        self.data_val = self.data[self.data['subset'] == 'val']\n\n    def generate_datasets(self):\n        self.ds_train = RGBDataset(\n            self.data_train.image.values, self.data_train.species_id.values, trans=A.Compose([\n                getattr(A, trans)(**params) for trans, params in self.train_trans.items()\n            ])\n            if self.train_trans is not None else None\n        )\n        self.ds_val = RGBDataset(\n            self.data_val.image.values, self.data_val.species_id.values)\n        self.ds_test = RGBDataset(self.data_test.image.values)\n\n    def print_dataset_info(self):\n        print('train:', len(self.ds_train))\n        print('val:', len(self.ds_val))\n        print('test:', len(self.ds_test))\n\n    def setup(self, stage=None):\n        self.data = self.read_data()\n        self.data['image'] = self.data['observation_id'].apply(get_patch_rgb)\n        self.data_test = self.read_data('test')\n        self.data_test['image'] = self.data_test['observation_id'].apply(\n            get_patch_rgb)\n        self.split_data()\n        self.generate_datasets()\n        self.print_dataset_info()\n\n    def get_dataloader(self, ds, batch_size=None, shuffle=None):\n        return DataLoader(\n            ds,\n            batch_size=batch_size if batch_size is not None else self.batch_size,\n            shuffle=shuffle if shuffle is not None else True,\n            num_workers=self.num_workers,\n            pin_memory=self.pin_memory\n        )\n\n    def train_dataloader(self, batch_size=None, shuffle=True):\n        return self.get_dataloader(self.ds_train, batch_size, shuffle)\n\n    def val_dataloader(self, batch_size=None, shuffle=False):\n        return self.get_dataloader(self.ds_val, batch_size, shuffle)\n\n    def test_dataloader(self, batch_size=None, shuffle=False):\n        return self.get_dataloader(self.ds_test, batch_size, shuffle)\n\n\nclass RGNirDataModule(RGBDataModule):\n    def __init__(self, batch_size=32, path=\"../input/geolifeclef-2022-lifeclef-2022-fgvc9\", num_workers=0, pin_memory=False, train_trans=None):\n        super().__init__(batch_size, path, num_workers, pin_memory, train_trans)\n\n    def generate_datasets(self):\n        self.ds_train = RGNirDataset(\n            self.data_train.observation_id.values, self.data_train.species_id.values, trans=A.Compose([\n                getattr(A, trans)(**params) for trans, params in self.train_trans.items()\n            ])\n            if self.train_trans is not None else None\n        )\n        self.ds_val = RGNirDataset(\n            self.data_val.observation_id.values, self.data_val.species_id.values)\n        self.ds_test = RGNirDataset(self.data_test.observation_id.values)\n\n    def setup(self, stage=None):\n        self.data = self.read_data()\n        self.data_test = self.read_data('test')\n        self.split_data()\n        self.generate_datasets()\n        self.print_dataset_info()\n\n\nclass RGBNirDataModule(RGNirDataModule):\n    def __init__(self, batch_size=32, path=\"../input/geolifeclef-2022-lifeclef-2022-fgvc9\", num_workers=0, pin_memory=False, train_trans=None):\n        super().__init__(batch_size, path, num_workers, pin_memory, train_trans)\n\n    def generate_datasets(self):\n        self.ds_train = RGBNirDataset(\n            self.data_train.observation_id.values, self.data_train.species_id.values, trans=A.Compose([\n                getattr(A, trans)(**params) for trans, params in self.train_trans.items()\n            ])\n            if self.train_trans is not None else None\n        )\n        self.ds_val = RGBNirDataset(\n            self.data_val.observation_id.values, self.data_val.species_id.values)\n        self.ds_test = RGBNirDataset(self.data_test.observation_id.values)\n\n\nclass RGBNirDataset(torch.utils.data.Dataset):\n    def __init__(self, observation_ids, labels=None, trans=None):\n        self.observation_ids = observation_ids\n        self.labels = labels\n        self.trans = trans\n\n    def __len__(self):\n        return len(self.observation_ids)\n\n    def __getitem__(self, ix):\n        observation_id = self.observation_ids[ix]\n        patch = get_patch(observation_id)\n        rgb = patch + '/' + str(observation_id) + '_rgb.jpg'\n        rgb = imread(rgb)\n        nir = patch + '/' + str(observation_id) + '_near_ir.jpg'\n        nir = imread(nir)\n        img = np.concatenate((rgb, np.expand_dims(nir, axis=-1)), axis=2)\n        if self.trans is not None:\n            img = self.trans(image=img)['image']\n        if self.labels is not None:\n            label = self.labels[ix]\n            return img, label\n        return img, observation_id\n\n\nclass RGBModule(pl.LightningModule):\n    def __init__(self, hparams):\n        super().__init__()\n        self.save_hyperparameters(hparams)\n        self.model = timm.create_model(\n            self.hparams.backbone,\n            pretrained=self.hparams.pretrained,\n            num_classes=17037\n        )\n\n    def forward(self, x):\n        x = x.float() / 255\n        x = x.permute(0, 3, 1, 2)\n        return self.model(x)\n\n    def predict(self, x):\n        self.eval()\n        with torch.no_grad():\n            preds = self(x.to(self.device))\n            return torch.softmax(preds, dim=1)\n\n    def shared_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = F.cross_entropy(y_hat, y)\n        error = top_30_error_rate(\n            y.cpu(), torch.softmax(y_hat, dim=1).cpu().detach())\n        return loss, error\n\n    def training_step(self, batch, batch_idx):\n        loss, error = self.shared_step(batch, batch_idx)\n        self.log('loss', loss)\n        self.log('error', error, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss, error = self.shared_step(batch, batch_idx)\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_error', error, prog_bar=True)\n\n    def configure_optimizers(self):\n        optimizer = getattr(torch.optim, self.hparams.optimizer)(self.parameters(),\n                                                                 **self.hparams['optimizer_params'])\n        return optimizer\n\n\nclass RGBNirModule(RGBModule):\n    def __init__(self, hparams):\n        super().__init__(hparams)\n        self.model = timm.create_model(\n            self.hparams.backbone,\n            pretrained=self.hparams.pretrained,\n            num_classes=17037,\n            in_chans=4,\n        )","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:15:19.537504Z","iopub.execute_input":"2022-05-22T15:15:19.537879Z","iopub.status.idle":"2022-05-22T15:15:49.114760Z","shell.execute_reply.started":"2022-05-22T15:15:19.537849Z","shell.execute_reply":"2022-05-22T15:15:49.113708Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Dataset Module","metadata":{}},{"cell_type":"code","source":"dm =RGBNirDataModule()\ndm.setup()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:15:49.116614Z","iopub.execute_input":"2022-05-22T15:15:49.116874Z","iopub.status.idle":"2022-05-22T15:15:51.733325Z","shell.execute_reply.started":"2022-05-22T15:15:49.116839Z","shell.execute_reply":"2022-05-22T15:15:51.732358Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Checking wether the Data has been loaded","metadata":{}},{"cell_type":"code","source":"imgs, labels = next(iter(dm.train_dataloader(batch_size=25)))\nimgs.shape, imgs.dtype, imgs.max(), imgs.min(), labels","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:15:51.735193Z","iopub.execute_input":"2022-05-22T15:15:51.735442Z","iopub.status.idle":"2022-05-22T15:15:52.938107Z","shell.execute_reply.started":"2022-05-22T15:15:51.735413Z","shell.execute_reply":"2022-05-22T15:15:52.937480Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# plot images in a 2x5 grid\nfig = plt.figure(figsize=(15,5))\nfor i in range(5):\n    ax = plt.subplot(2, 5, i+1)\n    ax.imshow(imgs[i][...,:3])\n    ax.set_title('rgb')\n    ax.axis('off')\n    ax = plt.subplot(2, 5, i+1+5)\n    ax.set_title('nir')\n    ax.imshow(imgs[i][...,3])\n    ax.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:15:52.939370Z","iopub.execute_input":"2022-05-22T15:15:52.939772Z","iopub.status.idle":"2022-05-22T15:15:53.912517Z","shell.execute_reply.started":"2022-05-22T15:15:52.939727Z","shell.execute_reply":"2022-05-22T15:15:53.911520Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Setting Base model parameters","metadata":{}},{"cell_type":"code","source":"hparams = {\n    'backbone': 'resnet18',\n    'pretrained': True,\n    'optimzier': 'Adam',\n    'optimizer_params': {\n        'lr': 1e-3\n    }\n}\n\nmodule = RGBNirModule(hparams)\noutputs = module(imgs)\noutputs.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:15:53.913735Z","iopub.execute_input":"2022-05-22T15:15:53.913967Z","iopub.status.idle":"2022-05-22T15:15:58.810380Z","shell.execute_reply.started":"2022-05-22T15:15:53.913938Z","shell.execute_reply":"2022-05-22T15:15:58.809574Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Training Steps","metadata":{}},{"cell_type":"code","source":"import pytorch_lightning as pl\n\nhparams = {\n    'datamodule': {\n        'batch_size': 64,\n        'num_workers': 2,\n        'pin_memory': False\n    },\n    'backbone': 'resnet18',\n    'pretrained': True,\n    'optimizer': 'Adam',\n    'optimizer_params': {\n        'lr': 1e-3\n    }\n}\n\n\ndm = RGBNirDataModule(**hparams['datamodule'])\ndm.setup()\nmodule = RGBNirModule(hparams)\n\ntrainer = pl.Trainer(\n    gpus=[0],\n    max_epochs=10,\n    enable_checkpointing=False,\n    logger=None,\n    overfit_batches=0\n)\n\ntrainer.fit(module, dm)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:15:58.813699Z","iopub.execute_input":"2022-05-22T15:15:58.813952Z","iopub.status.idle":"2022-05-22T15:16:01.771062Z","shell.execute_reply.started":"2022-05-22T15:15:58.813925Z","shell.execute_reply":"2022-05-22T15:16:01.769509Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dm = RGBNirDataModule(batch_size=64, pin_memory=True)\ndm.setup()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:16:01.772465Z","iopub.status.idle":"2022-05-22T15:16:01.773395Z","shell.execute_reply.started":"2022-05-22T15:16:01.773093Z","shell.execute_reply":"2022-05-22T15:16:01.773121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating Top-30 Error Rate","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nfrom GLC.metrics import top_30_error_rate\nimport numpy as np \n\nmodule.cuda(0)\ndl = dm.val_dataloader()\naccs = []\nfor imgs, labels in tqdm(dl):\n    preds = module.predict(imgs)\n\n    accs.append(top_30_error_rate(labels, preds.cpu()))\nnp.mean(accs)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:16:01.774462Z","iopub.status.idle":"2022-05-22T15:16:01.775365Z","shell.execute_reply.started":"2022-05-22T15:16:01.775134Z","shell.execute_reply":"2022-05-22T15:16:01.775158Z"},"trusted":true},"execution_count":null,"outputs":[]}]}